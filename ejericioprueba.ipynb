{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hbfLgIV0TSfu",
        "outputId": "79e78ca4-b5b7-487d-8ab4-fcf3750bd800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download\n",
            "To: /content/data_volunteers.json\n",
            "100%|██████████| 2.58M/2.58M [00:00<00:00, 17.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows utilizadas: 6033\n",
            "Max Input Length: 9\n",
            "Number of Input Words: 1800\n",
            "Max Output Length: 9\n",
            "Number of Output Words: 1805\n",
            "--2024-06-30 22:43:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-06-30 22:43:13--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-06-30 22:43:13--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 38s  \n",
            "\n",
            "2024-06-30 22:45:52 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Epoch 1/100\n",
            "76/76 [==============================] - 25s 282ms/step - loss: 3.0879 - accuracy: 0.5402 - val_loss: 2.5523 - val_accuracy: 0.5815\n",
            "Epoch 2/100\n",
            "76/76 [==============================] - 23s 302ms/step - loss: 2.3306 - accuracy: 0.5780 - val_loss: 2.2454 - val_accuracy: 0.6275\n",
            "Epoch 3/100\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 2.0237 - accuracy: 0.6265 - val_loss: 2.0136 - val_accuracy: 0.6455\n",
            "Epoch 4/100\n",
            "76/76 [==============================] - 21s 277ms/step - loss: 1.7529 - accuracy: 0.6773 - val_loss: 1.7832 - val_accuracy: 0.6945\n",
            "Epoch 5/100\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 1.5170 - accuracy: 0.7367 - val_loss: 1.6224 - val_accuracy: 0.7297\n",
            "Epoch 6/100\n",
            "76/76 [==============================] - 21s 272ms/step - loss: 1.3753 - accuracy: 0.7633 - val_loss: 1.5421 - val_accuracy: 0.7446\n",
            "Epoch 7/100\n",
            "76/76 [==============================] - 22s 289ms/step - loss: 1.2773 - accuracy: 0.7778 - val_loss: 1.4442 - val_accuracy: 0.7650\n",
            "Epoch 8/100\n",
            "76/76 [==============================] - 21s 274ms/step - loss: 1.1897 - accuracy: 0.7949 - val_loss: 1.3728 - val_accuracy: 0.7806\n",
            "Epoch 9/100\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1094 - accuracy: 0.8103 - val_loss: 1.3064 - val_accuracy: 0.7922\n",
            "Epoch 10/100\n",
            "76/76 [==============================] - 20s 265ms/step - loss: 1.0357 - accuracy: 0.8239 - val_loss: 1.2327 - val_accuracy: 0.8086\n",
            "Epoch 11/100\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 0.9678 - accuracy: 0.8380 - val_loss: 1.1789 - val_accuracy: 0.8138\n",
            "Epoch 12/100\n",
            "76/76 [==============================] - 20s 266ms/step - loss: 0.9064 - accuracy: 0.8488 - val_loss: 1.1161 - val_accuracy: 0.8302\n",
            "Epoch 13/100\n",
            "76/76 [==============================] - 23s 304ms/step - loss: 0.8528 - accuracy: 0.8593 - val_loss: 1.0668 - val_accuracy: 0.8369\n",
            "Epoch 14/100\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 0.8054 - accuracy: 0.8679 - val_loss: 1.0231 - val_accuracy: 0.8465\n",
            "Epoch 15/100\n",
            "76/76 [==============================] - 21s 275ms/step - loss: 0.7648 - accuracy: 0.8760 - val_loss: 0.9874 - val_accuracy: 0.8526\n",
            "Epoch 16/100\n",
            "76/76 [==============================] - 14s 177ms/step - loss: 0.7284 - accuracy: 0.8834 - val_loss: 0.9565 - val_accuracy: 0.8608\n",
            "Epoch 17/100\n",
            "76/76 [==============================] - 21s 280ms/step - loss: 0.6962 - accuracy: 0.8878 - val_loss: 0.9262 - val_accuracy: 0.8631\n",
            "Epoch 18/100\n",
            "76/76 [==============================] - 22s 285ms/step - loss: 0.6675 - accuracy: 0.8923 - val_loss: 0.9007 - val_accuracy: 0.8672\n",
            "Epoch 19/100\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 0.6417 - accuracy: 0.8964 - val_loss: 0.8796 - val_accuracy: 0.8710\n",
            "Epoch 20/100\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.6181 - accuracy: 0.8998 - val_loss: 0.8568 - val_accuracy: 0.8739\n",
            "Epoch 21/100\n",
            "76/76 [==============================] - 20s 264ms/step - loss: 0.5966 - accuracy: 0.9031 - val_loss: 0.8391 - val_accuracy: 0.8756\n",
            "Epoch 22/100\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 0.5762 - accuracy: 0.9066 - val_loss: 0.8188 - val_accuracy: 0.8801\n",
            "Epoch 23/100\n",
            "76/76 [==============================] - 21s 277ms/step - loss: 0.5572 - accuracy: 0.9097 - val_loss: 0.8012 - val_accuracy: 0.8822\n",
            "Epoch 24/100\n",
            "76/76 [==============================] - 23s 308ms/step - loss: 0.5393 - accuracy: 0.9126 - val_loss: 0.7853 - val_accuracy: 0.8855\n",
            "Epoch 25/100\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 0.5233 - accuracy: 0.9150 - val_loss: 0.7739 - val_accuracy: 0.8870\n",
            "Epoch 26/100\n",
            "76/76 [==============================] - 21s 283ms/step - loss: 0.5078 - accuracy: 0.9176 - val_loss: 0.7578 - val_accuracy: 0.8905\n",
            "Epoch 27/100\n",
            "76/76 [==============================] - 13s 164ms/step - loss: 0.4932 - accuracy: 0.9201 - val_loss: 0.7439 - val_accuracy: 0.8940\n",
            "Epoch 28/100\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 0.4793 - accuracy: 0.9223 - val_loss: 0.7318 - val_accuracy: 0.8956\n",
            "Epoch 29/100\n",
            "76/76 [==============================] - 23s 301ms/step - loss: 0.4667 - accuracy: 0.9246 - val_loss: 0.7199 - val_accuracy: 0.8976\n",
            "Epoch 30/100\n",
            "76/76 [==============================] - 21s 273ms/step - loss: 0.4545 - accuracy: 0.9261 - val_loss: 0.7108 - val_accuracy: 0.8998\n",
            "Epoch 31/100\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 0.4425 - accuracy: 0.9286 - val_loss: 0.6996 - val_accuracy: 0.9008\n",
            "Epoch 32/100\n",
            "76/76 [==============================] - 21s 273ms/step - loss: 0.4319 - accuracy: 0.9300 - val_loss: 0.6917 - val_accuracy: 0.9024\n",
            "Epoch 33/100\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 0.4211 - accuracy: 0.9313 - val_loss: 0.6829 - val_accuracy: 0.9041\n",
            "Epoch 34/100\n",
            "76/76 [==============================] - 23s 301ms/step - loss: 0.4111 - accuracy: 0.9330 - val_loss: 0.6747 - val_accuracy: 0.9061\n",
            "Epoch 35/100\n",
            "76/76 [==============================] - 21s 282ms/step - loss: 0.4015 - accuracy: 0.9345 - val_loss: 0.6673 - val_accuracy: 0.9070\n",
            "Epoch 36/100\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 0.3921 - accuracy: 0.9363 - val_loss: 0.6608 - val_accuracy: 0.9080\n",
            "Epoch 37/100\n",
            "76/76 [==============================] - 20s 265ms/step - loss: 0.3835 - accuracy: 0.9371 - val_loss: 0.6517 - val_accuracy: 0.9090\n",
            "Epoch 38/100\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 0.3749 - accuracy: 0.9382 - val_loss: 0.6455 - val_accuracy: 0.9104\n",
            "Epoch 39/100\n",
            "76/76 [==============================] - 22s 293ms/step - loss: 0.3666 - accuracy: 0.9393 - val_loss: 0.6373 - val_accuracy: 0.9118\n",
            "Epoch 40/100\n",
            "76/76 [==============================] - 30s 397ms/step - loss: 0.3588 - accuracy: 0.9408 - val_loss: 0.6301 - val_accuracy: 0.9132\n",
            "Epoch 41/100\n",
            "76/76 [==============================] - 20s 265ms/step - loss: 0.3513 - accuracy: 0.9415 - val_loss: 0.6246 - val_accuracy: 0.9146\n",
            "Epoch 42/100\n",
            "76/76 [==============================] - 20s 259ms/step - loss: 0.3437 - accuracy: 0.9427 - val_loss: 0.6202 - val_accuracy: 0.9152\n",
            "Epoch 43/100\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 0.3367 - accuracy: 0.9437 - val_loss: 0.6156 - val_accuracy: 0.9152\n",
            "Epoch 44/100\n",
            "76/76 [==============================] - 21s 283ms/step - loss: 0.3296 - accuracy: 0.9448 - val_loss: 0.6102 - val_accuracy: 0.9164\n",
            "Epoch 45/100\n",
            "76/76 [==============================] - 23s 305ms/step - loss: 0.3228 - accuracy: 0.9460 - val_loss: 0.6045 - val_accuracy: 0.9172\n",
            "Epoch 46/100\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 0.3164 - accuracy: 0.9472 - val_loss: 0.6018 - val_accuracy: 0.9177\n",
            "Epoch 47/100\n",
            "76/76 [==============================] - 21s 283ms/step - loss: 0.3098 - accuracy: 0.9480 - val_loss: 0.5955 - val_accuracy: 0.9181\n",
            "Epoch 48/100\n",
            "76/76 [==============================] - 16s 206ms/step - loss: 0.3039 - accuracy: 0.9493 - val_loss: 0.5895 - val_accuracy: 0.9188\n",
            "Epoch 49/100\n",
            "76/76 [==============================] - 22s 294ms/step - loss: 0.2977 - accuracy: 0.9503 - val_loss: 0.5877 - val_accuracy: 0.9188\n",
            "Epoch 50/100\n",
            "76/76 [==============================] - 23s 300ms/step - loss: 0.2921 - accuracy: 0.9511 - val_loss: 0.5832 - val_accuracy: 0.9203\n",
            "Epoch 51/100\n",
            "76/76 [==============================] - 20s 263ms/step - loss: 0.2864 - accuracy: 0.9520 - val_loss: 0.5780 - val_accuracy: 0.9206\n",
            "Epoch 52/100\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 0.2810 - accuracy: 0.9531 - val_loss: 0.5751 - val_accuracy: 0.9218\n",
            "Epoch 53/100\n",
            "76/76 [==============================] - 20s 266ms/step - loss: 0.2754 - accuracy: 0.9539 - val_loss: 0.5725 - val_accuracy: 0.9217\n",
            "Epoch 54/100\n",
            "76/76 [==============================] - 18s 237ms/step - loss: 0.2702 - accuracy: 0.9543 - val_loss: 0.5687 - val_accuracy: 0.9223\n",
            "Epoch 55/100\n",
            "76/76 [==============================] - 23s 300ms/step - loss: 0.2653 - accuracy: 0.9558 - val_loss: 0.5654 - val_accuracy: 0.9227\n",
            "Epoch 56/100\n",
            "76/76 [==============================] - 19s 249ms/step - loss: 0.2603 - accuracy: 0.9560 - val_loss: 0.5628 - val_accuracy: 0.9229\n",
            "Epoch 57/100\n",
            "76/76 [==============================] - 15s 200ms/step - loss: 0.2556 - accuracy: 0.9568 - val_loss: 0.5577 - val_accuracy: 0.9237\n",
            "Epoch 58/100\n",
            "76/76 [==============================] - 18s 239ms/step - loss: 0.2509 - accuracy: 0.9580 - val_loss: 0.5551 - val_accuracy: 0.9236\n",
            "Epoch 59/100\n",
            "76/76 [==============================] - 16s 208ms/step - loss: 0.2463 - accuracy: 0.9583 - val_loss: 0.5531 - val_accuracy: 0.9244\n",
            "Epoch 60/100\n",
            "76/76 [==============================] - 23s 305ms/step - loss: 0.2418 - accuracy: 0.9593 - val_loss: 0.5490 - val_accuracy: 0.9251\n",
            "Epoch 61/100\n",
            "76/76 [==============================] - 18s 235ms/step - loss: 0.2377 - accuracy: 0.9597 - val_loss: 0.5474 - val_accuracy: 0.9253\n",
            "Epoch 62/100\n",
            "76/76 [==============================] - 21s 275ms/step - loss: 0.2334 - accuracy: 0.9602 - val_loss: 0.5429 - val_accuracy: 0.9255\n",
            "Epoch 63/100\n",
            "76/76 [==============================] - 12s 162ms/step - loss: 0.2293 - accuracy: 0.9611 - val_loss: 0.5403 - val_accuracy: 0.9266\n",
            "Epoch 64/100\n",
            "76/76 [==============================] - 22s 284ms/step - loss: 0.2253 - accuracy: 0.9619 - val_loss: 0.5381 - val_accuracy: 0.9276\n",
            "Epoch 65/100\n",
            "76/76 [==============================] - 20s 261ms/step - loss: 0.2213 - accuracy: 0.9623 - val_loss: 0.5350 - val_accuracy: 0.9270\n",
            "Epoch 66/100\n",
            "76/76 [==============================] - 22s 296ms/step - loss: 0.2174 - accuracy: 0.9626 - val_loss: 0.5338 - val_accuracy: 0.9276\n",
            "Epoch 67/100\n",
            "76/76 [==============================] - 15s 201ms/step - loss: 0.2137 - accuracy: 0.9634 - val_loss: 0.5303 - val_accuracy: 0.9278\n",
            "Epoch 68/100\n",
            "76/76 [==============================] - 18s 241ms/step - loss: 0.2102 - accuracy: 0.9637 - val_loss: 0.5278 - val_accuracy: 0.9289\n",
            "Epoch 69/100\n",
            "76/76 [==============================] - 16s 206ms/step - loss: 0.2065 - accuracy: 0.9650 - val_loss: 0.5257 - val_accuracy: 0.9285\n",
            "Epoch 70/100\n",
            "76/76 [==============================] - 18s 239ms/step - loss: 0.2030 - accuracy: 0.9655 - val_loss: 0.5234 - val_accuracy: 0.9286\n",
            "Epoch 71/100\n",
            "76/76 [==============================] - 23s 304ms/step - loss: 0.1996 - accuracy: 0.9661 - val_loss: 0.5214 - val_accuracy: 0.9299\n",
            "Epoch 72/100\n",
            "76/76 [==============================] - 19s 246ms/step - loss: 0.1963 - accuracy: 0.9664 - val_loss: 0.5199 - val_accuracy: 0.9294\n",
            "Epoch 73/100\n",
            "76/76 [==============================] - 20s 258ms/step - loss: 0.1932 - accuracy: 0.9671 - val_loss: 0.5172 - val_accuracy: 0.9294\n",
            "Epoch 74/100\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 0.1898 - accuracy: 0.9681 - val_loss: 0.5160 - val_accuracy: 0.9295\n",
            "Epoch 75/100\n",
            "76/76 [==============================] - 21s 271ms/step - loss: 0.1869 - accuracy: 0.9683 - val_loss: 0.5143 - val_accuracy: 0.9297\n",
            "Epoch 76/100\n",
            "76/76 [==============================] - 22s 294ms/step - loss: 0.1837 - accuracy: 0.9689 - val_loss: 0.5128 - val_accuracy: 0.9302\n",
            "Epoch 77/100\n",
            "76/76 [==============================] - 21s 280ms/step - loss: 0.1809 - accuracy: 0.9695 - val_loss: 0.5115 - val_accuracy: 0.9296\n",
            "Epoch 78/100\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 0.1779 - accuracy: 0.9707 - val_loss: 0.5085 - val_accuracy: 0.9305\n",
            "Epoch 79/100\n",
            "76/76 [==============================] - 20s 267ms/step - loss: 0.1752 - accuracy: 0.9707 - val_loss: 0.5074 - val_accuracy: 0.9310\n",
            "Epoch 80/100\n",
            "76/76 [==============================] - 15s 199ms/step - loss: 0.1724 - accuracy: 0.9716 - val_loss: 0.5048 - val_accuracy: 0.9309\n",
            "Epoch 81/100\n",
            "76/76 [==============================] - 22s 291ms/step - loss: 0.1697 - accuracy: 0.9721 - val_loss: 0.5044 - val_accuracy: 0.9307\n",
            "Epoch 82/100\n",
            "76/76 [==============================] - 23s 303ms/step - loss: 0.1669 - accuracy: 0.9728 - val_loss: 0.5026 - val_accuracy: 0.9312\n",
            "Epoch 83/100\n",
            "76/76 [==============================] - 19s 247ms/step - loss: 0.1643 - accuracy: 0.9733 - val_loss: 0.5009 - val_accuracy: 0.9320\n",
            "Epoch 84/100\n",
            "76/76 [==============================] - 15s 199ms/step - loss: 0.1618 - accuracy: 0.9743 - val_loss: 0.4992 - val_accuracy: 0.9321\n",
            "Epoch 85/100\n",
            "76/76 [==============================] - 19s 249ms/step - loss: 0.1593 - accuracy: 0.9749 - val_loss: 0.4982 - val_accuracy: 0.9321\n",
            "Epoch 86/100\n",
            "76/76 [==============================] - 21s 281ms/step - loss: 0.1569 - accuracy: 0.9753 - val_loss: 0.4969 - val_accuracy: 0.9323\n",
            "Epoch 87/100\n",
            "76/76 [==============================] - 23s 304ms/step - loss: 0.1545 - accuracy: 0.9760 - val_loss: 0.4957 - val_accuracy: 0.9322\n",
            "Epoch 88/100\n",
            "76/76 [==============================] - 16s 206ms/step - loss: 0.1520 - accuracy: 0.9767 - val_loss: 0.4943 - val_accuracy: 0.9327\n",
            "Epoch 89/100\n",
            "76/76 [==============================] - 18s 242ms/step - loss: 0.1497 - accuracy: 0.9776 - val_loss: 0.4929 - val_accuracy: 0.9331\n",
            "Epoch 90/100\n",
            "76/76 [==============================] - 16s 209ms/step - loss: 0.1473 - accuracy: 0.9782 - val_loss: 0.4910 - val_accuracy: 0.9334\n",
            "Epoch 91/100\n",
            "76/76 [==============================] - 18s 237ms/step - loss: 0.1452 - accuracy: 0.9781 - val_loss: 0.4903 - val_accuracy: 0.9327\n",
            "Epoch 92/100\n",
            "76/76 [==============================] - 23s 297ms/step - loss: 0.1430 - accuracy: 0.9792 - val_loss: 0.4897 - val_accuracy: 0.9330\n",
            "Epoch 93/100\n",
            "76/76 [==============================] - 20s 258ms/step - loss: 0.1407 - accuracy: 0.9795 - val_loss: 0.4884 - val_accuracy: 0.9334\n",
            "Epoch 94/100\n",
            "76/76 [==============================] - 19s 254ms/step - loss: 0.1387 - accuracy: 0.9803 - val_loss: 0.4873 - val_accuracy: 0.9332\n",
            "Epoch 95/100\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 0.1366 - accuracy: 0.9802 - val_loss: 0.4857 - val_accuracy: 0.9335\n",
            "Epoch 96/100\n",
            "76/76 [==============================] - 20s 270ms/step - loss: 0.1345 - accuracy: 0.9811 - val_loss: 0.4847 - val_accuracy: 0.9336\n",
            "Epoch 97/100\n",
            "76/76 [==============================] - 22s 292ms/step - loss: 0.1326 - accuracy: 0.9817 - val_loss: 0.4836 - val_accuracy: 0.9338\n",
            "Epoch 98/100\n",
            "76/76 [==============================] - 23s 300ms/step - loss: 0.1306 - accuracy: 0.9818 - val_loss: 0.4832 - val_accuracy: 0.9346\n",
            "Epoch 99/100\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 0.1287 - accuracy: 0.9827 - val_loss: 0.4822 - val_accuracy: 0.9344\n",
            "Epoch 100/100\n",
            "76/76 [==============================] - 21s 272ms/step - loss: 0.1267 - accuracy: 0.9829 - val_loss: 0.4819 - val_accuracy: 0.9338\n",
            "1/1 [==============================] - 1s 866ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'<start>'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-57293e3aa568>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;31m# Probar el modelo con una secuencia de entrada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mtest_input_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decoded:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-57293e3aa568>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mstop_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '<start>'"
          ]
        }
      ],
      "source": [
        "# Instalación de dependencias necesarias\n",
        "!pip install --upgrade --no-cache-dir gdown --quiet\n",
        "\n",
        "# Importar librerías necesarias\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "import os\n",
        "import gdown\n",
        "import json\n",
        "\n",
        "# Descargar la carpeta de dataset\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")\n",
        "\n",
        "# Cargar el dataset\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario\n",
        "\n",
        "# Observar los campos disponibles en cada línea del dataset\n",
        "data[0].keys()\n",
        "\n",
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "\n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # Vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "\n",
        "        # output sentence (decoder_output) tiene\n",
        "        output_sentence = output + ' '\n",
        "        # output sentence input (decoder_input) tiene\n",
        "        output_sentence_input = ' ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))\n",
        "\n",
        "# Tokenizar las oraciones de entrada\n",
        "tokenizer_inputs = Tokenizer()\n",
        "tokenizer_inputs.fit_on_texts(input_sentences)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_sentences)\n",
        "\n",
        "# Encontrar la longitud máxima de las oraciones de entrada\n",
        "max_input_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Crear el diccionario de palabras para las oraciones de entrada\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "num_words_input = len(word2idx_inputs) + 1\n",
        "\n",
        "# Tokenizar las oraciones de salida\n",
        "tokenizer_outputs = Tokenizer()\n",
        "tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n",
        "output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "# Encontrar la longitud máxima de las oraciones de salida\n",
        "max_output_len = max(len(seq) for seq in output_sequences)\n",
        "\n",
        "# Crear el diccionario de palabras para las oraciones de salida\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# Padding de las secuencias para tener una longitud fija\n",
        "encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_len)\n",
        "decoder_input_sequences = pad_sequences(output_sequences_inputs, maxlen=max_output_len)\n",
        "decoder_output_sequences = pad_sequences(output_sequences, maxlen=max_output_len)\n",
        "\n",
        "print(f'Max Input Length: {max_input_len}')\n",
        "print(f'Number of Input Words: {num_words_input}')\n",
        "print(f'Max Output Length: {max_output_len}')\n",
        "print(f'Number of Output Words: {num_words_output}')\n",
        "\n",
        "# Descargar los embeddings de GloVe\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n",
        "\n",
        "# Cargar los embeddings de GloVe en un diccionario\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coeffs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coeffs\n",
        "\n",
        "# Crear la matriz de embeddings para las palabras en el diccionario de entrada\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((num_words_input, embedding_dim))\n",
        "for word, idx in word2idx_inputs.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "# Definir el modelo\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_len,))\n",
        "embedding_layer = Embedding(num_words_input, embedding_dim, weights=[embedding_matrix], input_length=max_input_len, trainable=False)\n",
        "encoder_embeddings = embedding_layer(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_output_len,))\n",
        "decoder_embedding_layer = Embedding(num_words_output, embedding_dim)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Modelo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convertir las secuencias de salida a un formato adecuado\n",
        "decoder_targets = np.expand_dims(decoder_output_sequences, -1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit([encoder_input_sequences, decoder_input_sequences], decoder_targets, batch_size=64, epochs=100, validation_split=0.2)\n",
        "\n",
        "# Modelo de Inferencia del Encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Modelo de Inferencia del Decoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_embeddings2 = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embeddings2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Función para generar respuestas\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<start>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tokenizer_outputs.index_word[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        if sampled_token == '<end>' or len(decoded_sentence) > max_output_len:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Probar el modelo con una secuencia de entrada\n",
        "test_input_seq = encoder_input_sequences[0:1]\n",
        "decoded_sentence = decode_sequence(test_input_seq)\n",
        "print('Input:', input_sentences[0])\n",
        "print('Decoded:', decoded_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para generar respuestas\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tokenizer_outputs.index_word[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        if sampled_token == 'end' or len(decoded_sentence) > max_output_len:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Probar el modelo con una secuencia de entrada\n",
        "test_input_seq = encoder_input_sequences[0:1]\n",
        "decoded_sentence = decode_sequence(test_input_seq)\n",
        "print('Input:', input_sentences[0])\n",
        "print('Decoded:', decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQMqR_y6dURE",
        "outputId": "45de7ab1-fdeb-4261-ee01-348800cb4aa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 470ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Input: hello \n",
            "Decoded:  by by by by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de dependencias necesarias\n",
        "!pip install --upgrade --no-cache-dir gdown --quiet\n",
        "!pip install wget --quiet\n",
        "\n",
        "# Importar librerías necesarias\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "import os\n",
        "import gdown\n",
        "import json\n",
        "import wget\n",
        "\n",
        "# Descargar la carpeta de dataset\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")\n",
        "\n",
        "# Cargar el dataset\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario\n",
        "\n",
        "# Observar los campos disponibles en cada línea del dataset\n",
        "data[0].keys()\n",
        "\n",
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 10  # Cambiamos max_len a 10 según las recomendaciones\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = txt.replace(\"\\'d\", \" had\")\n",
        "    txt = txt.replace(\"\\'s\", \" is\")\n",
        "    txt = txt.replace(\"\\'m\", \" am\")\n",
        "    txt = txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "\n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # Vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "\n",
        "        # output sentence (decoder_output) tiene\n",
        "        output_sentence = '<start> ' + output + ' <end>'\n",
        "        # output sentence input (decoder_input) tiene\n",
        "        output_sentence_input = '<start> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))\n",
        "\n",
        "# Tokenizar las oraciones de entrada\n",
        "tokenizer_inputs = Tokenizer(num_words=8000)  # MAX_VOCAB_SIZE = 8000\n",
        "tokenizer_inputs.fit_on_texts(input_sentences)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_sentences)\n",
        "\n",
        "# Encontrar la longitud máxima de las oraciones de entrada\n",
        "max_input_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Crear el diccionario de palabras para las oraciones de entrada\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "num_words_input = min(8000, len(word2idx_inputs) + 1)\n",
        "\n",
        "# Tokenizar las oraciones de salida\n",
        "tokenizer_outputs = Tokenizer(num_words=8000, filters='')  # MAX_VOCAB_SIZE = 8000\n",
        "tokenizer_outputs.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_sequences = tokenizer_outputs.texts_to_sequences(output_sentences)\n",
        "output_sequences_inputs = tokenizer_outputs.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "# Encontrar la longitud máxima de las oraciones de salida\n",
        "max_output_len = max(len(seq) for seq in output_sequences)\n",
        "\n",
        "# Crear el diccionario de palabras para las oraciones de salida\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "num_words_output = min(8000, len(word2idx_outputs) + 1)\n",
        "\n",
        "# Padding de las secuencias para tener una longitud fija\n",
        "encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_len)\n",
        "decoder_input_sequences = pad_sequences(output_sequences_inputs, maxlen=max_output_len)\n",
        "decoder_output_sequences = pad_sequences(output_sequences, maxlen=max_output_len)\n",
        "\n",
        "print(f'Max Input Length: {max_input_len}')\n",
        "print(f'Number of Input Words: {num_words_input}')\n",
        "print(f'Max Output Length: {max_output_len}')\n",
        "print(f'Number of Output Words: {num_words_output}')\n",
        "\n",
        "# Descargar los embeddings de FastText\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "!gunzip cc.en.300.vec.gz\n",
        "\n",
        "# Cargar los embeddings de FastText en un diccionario\n",
        "embeddings_index = {}\n",
        "with open('cc.en.300.vec', 'r', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coeffs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coeffs\n",
        "\n",
        "# Crear la matriz de embeddings para las palabras en el diccionario de entrada\n",
        "embedding_dim = 300  # Embeddings 300 Fasttext\n",
        "embedding_matrix = np.zeros((num_words_input, embedding_dim))\n",
        "for word, idx in word2idx_inputs.items():\n",
        "    if idx < num_words_input:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "# Definir el modelo\n",
        "latent_dim = 128  # n_units = 128\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_input_len,))\n",
        "embedding_layer = Embedding(num_words_input, embedding_dim, weights=[embedding_matrix], input_length=max_input_len, trainable=False)\n",
        "encoder_embeddings = embedding_layer(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True, dropout=0.2)  # LSTM Dropout 0.2\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_output_len,))\n",
        "decoder_embedding_layer = Embedding(num_words_output, embedding_dim)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2)  # LSTM Dropout 0.2\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Modelo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convertir las secuencias de salida a un formato adecuado\n",
        "decoder_targets = np.expand_dims(decoder_output_sequences, -1)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit([encoder_input_sequences, decoder_input_sequences], decoder_targets, batch_size=64, epochs=30, validation_split=0.2)  # Epochs 30~50\n",
        "\n",
        "# Modelo de Inferencia del Encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Modelo de Inferencia del Decoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_embeddings2 = decoder_embedding_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embeddings2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Función para generar respuestas\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tokenizer_outputs.index_word[sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        if sampled_token == 'end' or len(decoded_sentence) > max_output_len:\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Preguntas de prueba\n",
        "test_questions = [\n",
        "    \"Do you read?\",\n",
        "    \"Do you have any pet?\",\n",
        "    \"Where are you from?\"\n",
        "]\n",
        "\n",
        "# Generar respuestas para las preguntas de prueba\n",
        "for question in test_questions:\n",
        "    input_seq = tokenizer_inputs.texts_to_sequences([question])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_input_len)\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(f'Question: {question}')\n",
        "    print(f'Bot Response: {decoded_sentence}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3xvr40Tyd59g",
        "outputId": "42193eee-3bdc-416c-8921-f96406da47e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "El dataset ya se encuentra descargado\n",
            "Cantidad de rows utilizadas: 388\n",
            "Max Input Length: 4\n",
            "Number of Input Words: 142\n",
            "Max Output Length: 5\n",
            "Number of Output Words: 158\n",
            "--2024-06-30 23:25:54--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.25, 13.226.210.78, 13.226.210.111, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.en.300.vec.gz’\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G  44.5MB/s    in 17s     \n",
            "\n",
            "2024-06-30 23:26:11 (73.5 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 7s 538ms/step - loss: 4.8889 - accuracy: 0.3497 - val_loss: 4.5769 - val_accuracy: 0.5205\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 4.0705 - accuracy: 0.5194 - val_loss: 3.3473 - val_accuracy: 0.5744\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 2.8826 - accuracy: 0.5561 - val_loss: 2.6082 - val_accuracy: 0.5744\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 2.3644 - accuracy: 0.5568 - val_loss: 2.2845 - val_accuracy: 0.6000\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 2.0976 - accuracy: 0.6200 - val_loss: 2.0661 - val_accuracy: 0.7000\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 1.8927 - accuracy: 0.7000 - val_loss: 1.8884 - val_accuracy: 0.7333\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 1.7509 - accuracy: 0.7084 - val_loss: 1.7823 - val_accuracy: 0.7282\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 121ms/step - loss: 1.6318 - accuracy: 0.7103 - val_loss: 1.6683 - val_accuracy: 0.7333\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 106ms/step - loss: 1.5384 - accuracy: 0.7110 - val_loss: 1.6083 - val_accuracy: 0.7333\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 1.4920 - accuracy: 0.7103 - val_loss: 1.5573 - val_accuracy: 0.7333\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 1.4305 - accuracy: 0.7110 - val_loss: 1.5263 - val_accuracy: 0.7333\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 1.3909 - accuracy: 0.7110 - val_loss: 1.4865 - val_accuracy: 0.7333\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 117ms/step - loss: 1.3635 - accuracy: 0.7110 - val_loss: 1.4799 - val_accuracy: 0.7333\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 1.3349 - accuracy: 0.7219 - val_loss: 1.4444 - val_accuracy: 0.7487\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 112ms/step - loss: 1.2951 - accuracy: 0.7368 - val_loss: 1.4347 - val_accuracy: 0.7487\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 1.2886 - accuracy: 0.7303 - val_loss: 1.4271 - val_accuracy: 0.7513\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.2573 - accuracy: 0.7400 - val_loss: 1.4005 - val_accuracy: 0.7487\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.2291 - accuracy: 0.7406 - val_loss: 1.3943 - val_accuracy: 0.7513\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 1.2277 - accuracy: 0.7310 - val_loss: 1.3852 - val_accuracy: 0.7487\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 1.1976 - accuracy: 0.7394 - val_loss: 1.3700 - val_accuracy: 0.7513\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.1702 - accuracy: 0.7406 - val_loss: 1.3714 - val_accuracy: 0.7436\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 1.1767 - accuracy: 0.7419 - val_loss: 1.3693 - val_accuracy: 0.7513\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 1.1467 - accuracy: 0.7445 - val_loss: 1.3496 - val_accuracy: 0.7487\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 1.1250 - accuracy: 0.7452 - val_loss: 1.3501 - val_accuracy: 0.7513\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 1.1298 - accuracy: 0.7465 - val_loss: 1.3949 - val_accuracy: 0.7256\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 1.1116 - accuracy: 0.7477 - val_loss: 1.3327 - val_accuracy: 0.7513\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 119ms/step - loss: 1.0853 - accuracy: 0.7484 - val_loss: 1.3340 - val_accuracy: 0.7513\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 1.0840 - accuracy: 0.7555 - val_loss: 1.4035 - val_accuracy: 0.7179\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1.0913 - accuracy: 0.7490 - val_loss: 1.3261 - val_accuracy: 0.7513\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 1.0540 - accuracy: 0.7535 - val_loss: 1.3315 - val_accuracy: 0.7462\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3dfd7194385f>\u001b[0m in \u001b[0;36m<cell line: 214>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_input_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Question: {question}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Bot Response: {decoded_sentence}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-3dfd7194385f>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0msampled_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msampled_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}